{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "10SgesKXkj3k"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKdLGvgemFot"
      },
      "source": [
        "# Ví dụ về Autograd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btUmqIxzmBoH",
        "outputId": "f5b73370-ad75-4ad8-af0a-035fcefc5db7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x.grad:  tensor(3.)\n",
            "w.grad:  tensor(5.)\n",
            "b.grad:  tensor(1.)\n"
          ]
        }
      ],
      "source": [
        "# Xây dựng đồ thị tính toán với phương trình: y = 5*x + 10\n",
        "x = torch.tensor(5., requires_grad=True)\n",
        "w = torch.tensor(3., requires_grad=True)\n",
        "b = torch.tensor(10., requires_grad=True)\n",
        "\n",
        "y = w*x + b\n",
        "\n",
        "# Thực hiện tính gradients.\n",
        "y.backward()\n",
        "\n",
        "print(\"x.grad: \", x.grad)\n",
        "print(\"w.grad: \", w.grad)\n",
        "print(\"b.grad: \", b.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atevqor-n_Z8"
      },
      "source": [
        "# Ví dụ về Autograd (tiếp theo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jbb4GNRGoCla",
        "outputId": "240c6e2e-4d1c-42d4-b784-088ed10683d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "w:  Parameter containing:\n",
            "tensor([[ 0.3590, -0.4424,  0.2856, -0.2533],\n",
            "        [-0.0184, -0.4492,  0.0044,  0.2750],\n",
            "        [-0.4786, -0.3913,  0.3261,  0.2091]], requires_grad=True)\n",
            "b:  Parameter containing:\n",
            "tensor([ 0.4702, -0.2477,  0.4032], requires_grad=True)\n",
            "loss:  1.0402820110321045\n",
            "dL/dW:  tensor([[-0.1518, -0.1619,  0.3419, -0.3265],\n",
            "        [-0.0149,  0.2259, -0.2498,  0.3257],\n",
            "        [-0.1852, -0.1724,  0.1863,  0.0063]])\n",
            "dL/dB:  tensor([0.1047, 0.0153, 0.4232])\n",
            "loss after 1 step optimization:  1.0395008325576782\n"
          ]
        }
      ],
      "source": [
        "# Tạo 2 tensor x, y có kích thước lần lượt là (10, 4) và (10, 3)\n",
        "x = torch.randn(10, 4)\n",
        "y = torch.randn(10, 3)\n",
        "\n",
        "# Tạo fully connected layer\n",
        "linear_layer = nn.Linear(4, 3)\n",
        "print(\"w: \", linear_layer.weight)\n",
        "print(\"b: \", linear_layer.bias)\n",
        "\n",
        "# Xây dựng hàm loss và optimizer \n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(linear_layer.parameters(), lr=0.001)\n",
        "\n",
        "# Lan truyền tiến \n",
        "forward = linear_layer(x)\n",
        "\n",
        "# Tính giá trị loss\n",
        "loss = criterion(forward, y)\n",
        "print(\"loss: \", loss.item())\n",
        "\n",
        "# Lan truyền ngược\n",
        "loss.backward()\n",
        "\n",
        "# Xuất giá trị đạo hàm\n",
        "print(\"dL/dW: \", linear_layer.weight.grad)\n",
        "print(\"dL/dB: \", linear_layer.bias.grad)\n",
        "\n",
        "optimizer.step()\n",
        "\n",
        "# Xuất kết quả sau một bước đaọ hàm\n",
        "pred = linear_layer(x)\n",
        "loss = criterion(pred, y)\n",
        "print('loss after 1 step optimization: ', loss.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPhG-NleWaN6"
      },
      "source": [
        "# Load dữ liệu với numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrq2fRxUVAB0",
        "outputId": "08ca4bda-afb7-4e37-8f77-7a1863e62d53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "type(y):  <class 'torch.Tensor'>\n",
            "type(z):  <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "x = np.array([[1, 2], [3, 4]])\n",
        "\n",
        "# Chuyển đổi numpy array sang torch tensor\n",
        "y = torch.from_numpy(x)\n",
        "print(\"type(y): \", type(y))\n",
        "\n",
        "# Chuyển đổi torch tensor sang numpy array\n",
        "z = y.numpy()\n",
        "print(\"type(z): \", type(z))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCZIiO1IXEoF"
      },
      "source": [
        "# Input pipeline "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-8F8Z1YKXKsF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [14:01<00:00, 203kB/s]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "size:  torch.Size([3, 32, 32])\n",
            "labelL:  6\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'_SingleProcessDataLoaderIter' object has no attribute 'next'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m data_iter = \u001b[38;5;28miter\u001b[39m(train_loader)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Thực hiện mini-batch trên các ảnh và nhãn tương ứng\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m images, labels = \u001b[43mdata_iter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnext\u001b[49m()\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Quá trình load ảnh thực tế được thực hiện như sau\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m image, label \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[32m     24\u001b[39m   \u001b[38;5;66;03m# Quá trình huấn luyện được thực hiện tại đây\u001b[39;00m\n",
            "\u001b[31mAttributeError\u001b[39m: '_SingleProcessDataLoaderIter' object has no attribute 'next'"
          ]
        }
      ],
      "source": [
        "# Sử dụng dữ liệu với torchvision.datasets\n",
        "train_dataset = torchvision.datasets.CIFAR10(root=\"./data\",\n",
        "                                             train=True,\n",
        "                                             transform=transforms.ToTensor(),\n",
        "                                             download=True)\n",
        "\n",
        "image, label = train_dataset[0]\n",
        "print(\"size: \", image.size())\n",
        "print(\"labelL: \", label)\n",
        "\n",
        "# DataLoader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=64,\n",
        "                                           shuffle=True)\n",
        "\n",
        "# Khi bắt đầu lặp, sẽ lần lượt đọc dữ liệu đưa vào queue và thread\n",
        "data_iter = iter(train_loader)\n",
        "\n",
        "# Thực hiện mini-batch trên các ảnh và nhãn tương ứng\n",
        "images, labels = data_iter.next()\n",
        "\n",
        "# Quá trình load ảnh thực tế được thực hiện như sau\n",
        "for image, label in train_loader:\n",
        "  # Quá trình huấn luyện được thực hiện tại đây\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkDtaLqmpAbr"
      },
      "source": [
        "# Input pipeline for custom dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miASpli5pKXQ"
      },
      "outputs": [],
      "source": [
        "# Xây dựng hàm xử lý cho custom dataset\n",
        "class CustomDataset(object): # torch.utils.data.Dataset\n",
        "  def __init__(self):\n",
        "    # Khởi tạo danh sách đường dẫn hình hoặc tên hình.\n",
        "    pass\n",
        "  \n",
        "  def get_item(self, index):\n",
        "    # Đọc data từ file (numpy.fromfile, PIL.Image.open)\n",
        "    # Tiền xử lý dữ liệ (torchvision.Transform)\n",
        "    # Trả về một cặp dữ liệu (image và label)\n",
        "    pass \n",
        "  \n",
        "  def __len__(self):\n",
        "    # Trả về số lượng mẫu trong dữ liệu \n",
        "    pass \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBQEIXR9qpj_"
      },
      "source": [
        "# Pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_36D_LUqs3N",
        "outputId": "7a1b0171-1e0b-473c-a6a5-4a9fc9842539"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output size:  torch.Size([64, 100])\n"
          ]
        }
      ],
      "source": [
        "# Sử dụng pretrained ResNet-18\n",
        "resnet = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "# Finetune model \n",
        "for param in resnet.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "# Thay thế top k layer đầu tiên cho finetuning\n",
        "resnet.fc = nn.Linear(resnet.fc.in_features, 100) # k = 100\n",
        "\n",
        "# Lan truyền tiến \n",
        "image = torch.rand(64, 3, 224, 224)\n",
        "outputs = resnet(image)\n",
        "print(\"output size: \", outputs.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7PVX_busNtW"
      },
      "source": [
        "# Save and Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7UqBb9LsRck",
        "outputId": "2b6c0987-e3df-4a2c-b975-bc8c0809b34b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load model....\n",
            "load params......\n"
          ]
        }
      ],
      "source": [
        "torch.save(resnet, \"model_resnet18.ckpt\")\n",
        "model = torch.load('model_resnet18.ckpt')\n",
        "print(\"load model....\")\n",
        "\n",
        "# Save and load only the model parameters (thường dùng).\n",
        "torch.save(resnet.state_dict(), 'params_resnet.ckpt')\n",
        "resnet.load_state_dict(torch.load('params_resnet.ckpt'))\n",
        "print(\"load params......\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "template.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
